{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b1e8f3-aab4-4dca-af24-41e2e4bdc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After performing a set of modifications to a notebook, \n",
    "# save the browser console logs to a file and insert it here. \n",
    "perf_log_file = \"logs/parse-runall.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071dab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f571ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type definitions: \n",
    "CellID = str\n",
    "TimeStampMS = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb79040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type definitions: \n",
    "CellID = str\n",
    "TimeStampMS = float\n",
    "\n",
    "# Life cycle of a rerun. \n",
    "# This represents a rerun segment in the log file. \n",
    "# \n",
    "# PERF T0: Rerun is started\n",
    "# PERF T1: Kernel receives message to run first cell\n",
    "#     At this point, all the rerun logic has finished.\n",
    "#     Any remaining time is up to the kernel => Firsst cell scheduled. \n",
    "# PERF T2: Last reran cells have finished running \n",
    "#           => Immediately onExectued \n",
    "# PERF T3: Rerun reports that all cells have finished running \n",
    "#           => Has some overhead with set checking. \n",
    "# For the sake of just calcuating overhead, we should just use T1 - T0. \n",
    "@dataclass\n",
    "class RerunPerfStat:\n",
    "    rerun_start_time: TimeStampMS = None # T0\n",
    "    rerun_end_time: TimeStampMS = None # T3\n",
    "    first_cell_schedule_time: TimeStampMS = float('inf') # T1\n",
    "    last_cell_executed_time: TimeStampMS = -float('inf') # T2\n",
    "\n",
    "    # reran_cells is used to identify which cell execution events are part\n",
    "    # of this rerun based on the cell IDs stored by the prints. \n",
    "    reran_cells: list[CellID] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecabe6b-36b2-4d11-a277-1bd5059d2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PerfStat:\n",
    "    PERF_LINE_DELIM = \"|\"\n",
    "    \n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Upon creation, PerfStat parses the input file\n",
    "        and generates the RerunPerfStats for further use.\n",
    "        \"\"\"\n",
    "        self._cell_scheduled_times = []\n",
    "        self._cell_executed_times = []\n",
    "\n",
    "        self._rerun_stats = [] # Holds all rerunPerfStats for the entire log file. \n",
    "        self._rerun_all_stats = [] # Holds all the rerunAllStats\n",
    "\n",
    "        # Two stage parsing process\n",
    "        # First _parse() populates _cell_scheduled_times, _cell_executed_times\n",
    "        # and _rerun_stats (effectively divids log file up into unique reran events). \n",
    "        self._parse(file_path)\n",
    "        # Then _match_cells_to_reruns sets the first_cell_schedule_time (T1)\n",
    "        # and last_cell_executed_time (T2) fields for each rerun found\n",
    "        # by _parse. \n",
    "        self._match_cells_to_reruns()\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_cell_event(tokens: list[str]) -> tuple[CellID, TimeStampMS]:\n",
    "        \"\"\"\n",
    "        There are two cell events:\n",
    "         -Scheduled: occurs when the kernel recieves the request\n",
    "                     to queue a cell for execution. \n",
    "         -Executed: emitted by the kernel once a cell has finished. \n",
    "         \n",
    "        The perf messages for cell events follow the format of\n",
    "        PERF|<Event> time=...|exec id=...|cell_id_token=...\n",
    "        \"\"\"\n",
    "        time_token, _, cell_id_token, _ = tokens\n",
    "        _, timestamp = time_token.split(\"=\")\n",
    "        _, cell_id = cell_id_token.split(\"=\")\n",
    "\n",
    "        return cell_id, float(timestamp)\n",
    "\n",
    "    def _handle_perf_line(self, line: str) -> None:\n",
    "        \"\"\"\n",
    "        Given a raw perf log line, parses it based on the perf event\n",
    "        and updates the parser datastructures. \n",
    "        \"\"\"\n",
    "        # First token is always PERF, skip\n",
    "        tokens = line.split(self.PERF_LINE_DELIM)[1:] # => Scheduled time=...|exec id=...|cell_id_token=...\n",
    "        \n",
    "        event_name_token = tokens[0] # Scheduled time\n",
    "        name, value = event_name_token.split(\"=\") # => Scheduled time, TIME \n",
    "        if name == \"Scheduled time\":\n",
    "            # Scheduled time=%f|exec id=%d|cell id=%s\n",
    "            # NOTE: We may have other cells not having to do with reran here. \n",
    "            cell_id, timestamp = self._parse_cell_event(tokens)\n",
    "            self._cell_scheduled_times.append((cell_id.strip(), timestamp)) # add to all cell scheduled time \n",
    "            \n",
    "        elif name == \"Executed time\":\n",
    "            # Executed time=%f|exec_id=%d|cell_id=%s\n",
    "            # NOTE: We may have other cells not having to do with reran here. \n",
    "            cell_id, timestamp = self._parse_cell_event(tokens)\n",
    "            self._cell_executed_times.append((cell_id.strip(), timestamp)) # add to all cell executed time\n",
    "            \n",
    "        elif name == \"Rerun start\":\n",
    "            # Rerun start=%d|Rerun cells=%s\n",
    "            rerun_stat = RerunPerfStat() # Create a new representation of a rerun event (segment). \n",
    "            rerun_stat.rerun_start_time = float(value)\n",
    "            _, rerun_cell_tokens = tokens[1].split(\"=\") # Get cells reran. \n",
    "            print(\"RERUN CELL TOKENS: \", [rerun_cell_tokens.strip()])\n",
    "            clean_rerun_cell_tokens = rerun_cell_tokens.strip()\n",
    "            if not clean_rerun_cell_tokens: \n",
    "                 rerun_stat.reran_cells = []\n",
    "                 rerun_stat.last_cell_executed_time = rerun_stat.rerun_start_time\n",
    "                 rerun_stat.first_cell_schedule_time = rerun_stat.rerun_start_time\n",
    "                 self._rerun_stats.append(rerun_stat)\n",
    "                 return \n",
    "            rerun_stat.reran_cells = [cell_id.strip() for cell_id in clean_rerun_cell_tokens.split(',')]\n",
    "            if (len(rerun_stat.reran_cells) == 0):\n",
    "                return \n",
    "            self._rerun_stats.append(rerun_stat)\n",
    "            \n",
    "        elif name == \"Rerun end\":\n",
    "            # Rerun end=%f\n",
    "            # This one is the rerun end time that has a little bit overhead. \n",
    "            latest_rerun = self._rerun_stats[-1] # Get the latest reran object. \n",
    "            latest_rerun.rerun_end_time = float(value) # Set their end time => this marks the end of a rerun segment.  \n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid perf event: {line}\")\n",
    "        \n",
    "    def _parse(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Iterates over each line of the log file \n",
    "        for perf events\n",
    "        \"\"\"\n",
    "        rerun_all_temp_holder = []\n",
    "        with open(file_path) as fd:\n",
    "            for line in fd:\n",
    "                line_start_idx = line.find(\"PERF\")\n",
    "                if line_start_idx != -1:\n",
    "                    \n",
    "                        self._handle_perf_line(line[line_start_idx:])\n",
    "\n",
    "    def _match_cell_start(self, cur_rerun: RerunPerfStat):\n",
    "        \"\"\"\n",
    "        Iterates through the list of Scheduled events (scheduled_times)\n",
    "        to find the Schedule event time of each reran cell in\n",
    "        cur_rerun.\n",
    "        \n",
    "        First cell to be scheduled for rerun: \n",
    "        Sets the first_cell_schedule_time using the\n",
    "        earliest Schedule event timestamp of reran cells. \n",
    "        \"\"\"\n",
    "        to_remove_idx = []\n",
    "        reran_cells = set(cur_rerun.reran_cells)\n",
    "        for idx, (cell_id, timestamp) in enumerate(self._cell_scheduled_times):\n",
    "            if not reran_cells:\n",
    "                break\n",
    "            \n",
    "            # Time is organized top (recent) -> bottom (past)\n",
    "            if cell_id in reran_cells and timestamp >= cur_rerun.rerun_start_time:\n",
    "                reran_cells.remove(cell_id)\n",
    "                cur_rerun.first_cell_schedule_time = min(\n",
    "                    cur_rerun.first_cell_schedule_time, timestamp\n",
    "                )\n",
    "                to_remove_idx.append(idx)\n",
    "        \n",
    "        # Remove all of this rerun segment cell's on schedule time since \n",
    "        # we already got the first scheduled cell's time. \n",
    "        self._cell_scheduled_times = [\n",
    "            cell for idx, cell in enumerate(self._cell_scheduled_times) if idx not in to_remove_idx\n",
    "        ]\n",
    "\n",
    "    def _match_cell_end(self, cur_rerun: RerunPerfStat):\n",
    "        \"\"\"\n",
    "        Iterates through the list of Executed events\n",
    "        to find the Executed event time of each reran cell in\n",
    "        cur_rerun. \n",
    "        \n",
    "        Sets the last_cell_executed_time using the\n",
    "        latest Exexcuted event timestamp of reran cells\n",
    "        \"\"\"\n",
    "        to_remove_idx = []\n",
    "        reran_cells = set(cur_rerun.reran_cells)\n",
    "        for idx, (cell_id, timestamp) in enumerate(self._cell_executed_times):\n",
    "            if not reran_cells:\n",
    "                break\n",
    "            \n",
    "            # All seen executed times will for sure be part of our rerun. \n",
    "            # Which means that they are the cells that got reran for this \n",
    "            # segment of the log file. \n",
    "            if cell_id in reran_cells:\n",
    "                reran_cells.remove(cell_id)\n",
    "                cur_rerun.last_cell_executed_time = max(\n",
    "                    cur_rerun.last_cell_executed_time, timestamp\n",
    "                )\n",
    "                to_remove_idx.append(idx)\n",
    "\n",
    "        # Remove all cells related to this rerun segment since we are done \n",
    "        # with it (extracted the last cell executed time). \n",
    "        self._cell_executed_times = [\n",
    "            cell for idx, cell in enumerate(self._cell_executed_times) if idx not in to_remove_idx\n",
    "        ]\n",
    "        \n",
    "    def _match_cells_to_reruns(self):\n",
    "        \"\"\"\n",
    "        For each rerun, match cell events to the rerun the\n",
    "        event was part of.\n",
    "        \"\"\"\n",
    "\n",
    "        # the earliest reruns are at the beginning of _rerun_stats list\n",
    "        # reverse the list so the earliest events are at the end\n",
    "        # then we pop the events off the end until rerun_queue is empty\n",
    "        rerun_queue = copy(self._rerun_stats)\n",
    "        rerun_queue.reverse()\n",
    "        \n",
    "        while rerun_queue:\n",
    "            cur_rerun = rerun_queue.pop()\n",
    "            self._match_cell_start(cur_rerun)\n",
    "            self._match_cell_end(cur_rerun)\n",
    "\n",
    "    @property\n",
    "    def rerun_perf_stats(self) -> list[RerunPerfStat]:\n",
    "        \"\"\" Public getter method to use the rerun stats for analysis. \"\"\"\n",
    "        return self._rerun_stats\n",
    "\n",
    "    def pretty_print_rerun_stats(self) -> None:\n",
    "        \"\"\" Formatted print of all rerun stats, cell ids are excluded. \"\"\"\n",
    "        out_msg = [\"Reruns:\"]\n",
    "        for idx, rerun in enumerate(self._rerun_stats):\n",
    "            rerun_msg = (\n",
    "                f\"Rerun idx: {idx}\\n\"\n",
    "                f\"Number of cells reran: {len(rerun.reran_cells)}\\n\"\n",
    "                f\"Rerun start timestamp: {rerun.rerun_start_time}ms\\n\"\n",
    "                f\"First cell scheduled timestamp: {rerun.first_cell_schedule_time}ms\\n\"\n",
    "                f\"Last cell executed timestamp: {rerun.last_cell_executed_time}ms\\n\"\n",
    "                f\"Rerun end timestamp: {rerun.rerun_end_time}ms\\n\"\n",
    "            )\n",
    "            out_msg.append(rerun_msg)\n",
    "        print(\"\\n\".join(out_msg))\n",
    "\n",
    "    def average_overhead(self) -> dict[int, list[float, int]]:\n",
    "        \"\"\"\n",
    "        Returns a dict\n",
    "        num cells in rerun -> average overhead of rerun in ms, num reruns. \n",
    "        see how rerun overhead changes as we get more cells that we need to rerun. \n",
    "        \"\"\"\n",
    "        ret = {}\n",
    "        for rerun in self._rerun_stats:\n",
    "            n_cells = len(rerun.reran_cells)\n",
    "            overhead = rerun.first_cell_schedule_time - rerun.rerun_start_time\n",
    "            if info := ret.get(n_cells):\n",
    "                info[0] += overhead\n",
    "                info[1] += 1 # accumulate reruns with this exact num of cells to rerun. \n",
    "            else:\n",
    "                ret[n_cells] = [overhead, 1]\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def average_totalRerunTime(self) -> dict[int, list[float, int]]:\n",
    "        \"\"\"\n",
    "        Returns a dict\n",
    "        modification -> average overhead of rerun in ms, cells reran  \n",
    "        see how rerun overhead changes as we get more cells that we need to rerun. \n",
    "        \"\"\"\n",
    "        ret = {}\n",
    "        for rerun in self._rerun_stats:\n",
    "            n_cells = len(rerun.reran_cells)\n",
    "            overhead = rerun.first_cell_schedule_time - rerun.rerun_start_time\n",
    "            if info := ret.get(n_cells):\n",
    "                info[0] += overhead\n",
    "                info[1] += 1 # accumulate reruns with this exact num of cells to rerun. \n",
    "            else:\n",
    "                ret[n_cells] = [overhead, 1]\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def total_rerun_execution_time(self) -> dict[int, list[float, int]]: \n",
    "        \"\"\" \n",
    "        Returns a dict \n",
    "        modification id -> time taken for all scheduled rerun cells to rerun, number of cells reran \n",
    "        \n",
    "        visualize total time to execute scheduled rerun cells \n",
    "        idenitfy if we can get better performance by not reruning unnecessary cells. \n",
    "        \"\"\" \n",
    "        ret = {}\n",
    "       \n",
    "        for rerun_id, rerun in enumerate(self._rerun_stats): \n",
    "            n_cells = len(rerun.reran_cells) \n",
    "            execution_time = rerun.last_cell_executed_time - rerun.first_cell_schedule_time \n",
    "            ret[rerun_id] = [execution_time, n_cells] \n",
    "        return ret\n",
    "    \n",
    "    def rerun_specific_overhead(self) -> dict[int, list[float, int]]: \n",
    "        \"\"\" \n",
    "        Returns a dict \n",
    "        modification id -> time taken to prepare for rerun, number of cells reran \n",
    "        \n",
    "        get each rerun specific overhead\n",
    "        help us visualize how long each rerun method takes to calculate \n",
    "        which cells should be reran. \n",
    "        \"\"\" \n",
    "        ret = {}\n",
    "       \n",
    "        for rerun_id, rerun in enumerate(self._rerun_stats): \n",
    "            n_cells = len(rerun.reran_cells) \n",
    "            overhead = rerun.first_cell_schedule_time - rerun.rerun_start_time\n",
    "            ret[rerun_id] = [overhead, n_cells] \n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709d505b-d2e0-480c-8411-26298d23d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RERUN CELL TOKENS:  ['7c32c6a2-28cc-4f19-b92c-43266d1560d1']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stat = \u001b[43mPerfStat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperf_log_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mPerfStat.__init__\u001b[39m\u001b[34m(self, file_path)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mself\u001b[39m._rerun_all_stats = [] \u001b[38;5;66;03m# Holds all the rerunAllStats\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Two stage parsing process\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# First _parse() populates _cell_scheduled_times, _cell_executed_times\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# and _rerun_stats (effectively divids log file up into unique reran events). \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Then _match_cells_to_reruns sets the first_cell_schedule_time (T1)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# and last_cell_executed_time (T2) fields for each rerun found\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# by _parse. \u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m._match_cells_to_reruns()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mPerfStat._parse\u001b[39m\u001b[34m(self, file_path)\u001b[39m\n\u001b[32m    104\u001b[39m         rerun_all_temp_holder.append(line)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_perf_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m[\u001b[49m\u001b[43mline_start_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mPerfStat._handle_perf_line\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m     47\u001b[39m tokens = line.split(\u001b[38;5;28mself\u001b[39m.PERF_LINE_DELIM)[\u001b[32m1\u001b[39m:] \u001b[38;5;66;03m# => Scheduled time=...|exec id=...|cell_id_token=...\u001b[39;00m\n\u001b[32m     49\u001b[39m event_name_token = tokens[\u001b[32m0\u001b[39m] \u001b[38;5;66;03m# Scheduled time\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m name, value = event_name_token.split(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# => Scheduled time, TIME \u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mScheduled time\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Scheduled time=%f|exec id=%d|cell id=%s\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# NOTE: We may have other cells not having to do with reran here. \u001b[39;00m\n\u001b[32m     54\u001b[39m     cell_id, timestamp = \u001b[38;5;28mself\u001b[39m._parse_cell_event(tokens)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "stat = PerfStat(perf_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b965c-a763-4f8d-bfc7-ee9395bad4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.pretty_print_rerun_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b07703-d46a-4d3b-8154-992740dc376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average rerun overhead: number of cells -> [avg time, number of reruns]')\n",
    "print(stat.average_overhead())\n",
    "\n",
    "print('All Total Reran Cell Execution time: rerun_id -> [time (ms), number of cells reran]')\n",
    "print(stat.total_rerun_execution_time())\n",
    "\n",
    "print('All Rerun Overhead: rerun_id -> [time (ms), number of cells reran]') \n",
    "print(stat.rerun_specific_overhead())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da020a-95d0-43f3-a6ac-5246d326ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_runtime_chart(rerun: RerunPerfStat) -> None:\n",
    "    processes = [\n",
    "        {\n",
    "            \"name\": \"Handling Rerun Signal\",\n",
    "            \"start\": 0,\n",
    "            \"stop\": rerun.first_cell_schedule_time - rerun.rerun_start_time,\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"Cells executing (Rerun)\",\n",
    "            \"start\": rerun.first_cell_schedule_time - rerun.rerun_start_time,\n",
    "            \"stop\": rerun.last_cell_executed_time - rerun.first_cell_schedule_time,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    process_names = [p[\"name\"] for p in processes]\n",
    "    start_times = [p[\"start\"] for p in processes]\n",
    "    durations = [p[\"stop\"] - p[\"start\"] for p in processes]\n",
    "    y_positions = np.arange(len(processes))\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot horizontal bars (Gantt chart)\n",
    "    plt.barh(y_positions, durations, left=start_times, height=0.4, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.yticks(y_positions, process_names)\n",
    "    plt.xlabel('Time (milliseconds)')\n",
    "    plt.ylabel('Processes')\n",
    "    plt.title('Process Latency (Start and Stop Times)')\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout to prevent label clipping\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb2632-42a1-4ae9-96fb-0744e1c58f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_average_runtime_chart(stat.rerun_perf_stats[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29c6c7-650e-4bdf-92b8-c4ad8bccf0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jlab-e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
