{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1e8f3-aab4-4dca-af24-41e2e4bdc922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T01:24:37.604698Z",
     "iopub.status.busy": "2025-04-18T01:24:37.602838Z",
     "iopub.status.idle": "2025-04-18T01:24:37.612326Z",
     "shell.execute_reply": "2025-04-18T01:24:37.611372Z",
     "shell.execute_reply.started": "2025-04-18T01:24:37.604614Z"
    }
   },
   "outputs": [],
   "source": [
    "# After performing a set of modifications to a notebook, \n",
    "# save the browser console logs to a file and insert it here. \n",
    "perf_log_file = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecabe6b-36b2-4d11-a277-1bd5059d2f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:57:24.066147Z",
     "iopub.status.busy": "2025-04-18T06:57:24.064679Z",
     "iopub.status.idle": "2025-04-18T06:57:24.094694Z",
     "shell.execute_reply": "2025-04-18T06:57:24.094298Z",
     "shell.execute_reply.started": "2025-04-18T06:57:24.066071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Type definitions: \n",
    "CellID = str\n",
    "TimeStampMS = float\n",
    "\n",
    "# Life cycle of a rerun. \n",
    "# This represents a rerun segment in the log file. \n",
    "# \n",
    "# PERF T0: Rerun is started\n",
    "# PERF T1: Kernel receives message to run first cell\n",
    "#     At this point, all the rerun logic has finished.\n",
    "#     Any remaining time is up to the kernel => Firsst cell scheduled. \n",
    "# PERF T2: Last reran cells have finished running \n",
    "#           => Immediately onExectued \n",
    "# PERF T3: Rerun reports that all cells have finished running \n",
    "#           => Has some overhead with set checking. \n",
    "# For the sake of just calcuating overhead, we should just use T1 - T0. \n",
    "@dataclass\n",
    "class RerunPerfStat:\n",
    "    rerun_start_time: TimeStampMS = None # T0\n",
    "    rerun_end_time: TimeStampMS = None # T3\n",
    "    first_cell_schedule_time: TimeStampMS = float('inf') # T1\n",
    "    last_cell_executed_time: TimeStampMS = -float('inf') # T2\n",
    "\n",
    "    # reran_cells is used to identify which cell execution events are part\n",
    "    # of this rerun based on the cell IDs stored by the prints. \n",
    "    reran_cells: list[CellID] = field(default_factory=list)\n",
    "\n",
    "class PerfStat:\n",
    "    PERF_LINE_DELIM = \"|\"\n",
    "    \n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Upon creation, PerfStat parses the input file\n",
    "        and generates the RerunPerfStats for further use.\n",
    "        \"\"\"\n",
    "        self._cell_scheduled_times = []\n",
    "        self._cell_executed_times = []\n",
    "\n",
    "        self._rerun_stats = [] # Holds all rerunPerfStats for the entire log file. \n",
    "\n",
    "        # Two stage parsing process\n",
    "        # First _parse() populates _cell_scheduled_times, _cell_executed_times\n",
    "        # and _rerun_stats (effectively divids log file up into unique reran events). \n",
    "        self._parse(file_path)\n",
    "        # Then _match_cells_to_reruns sets the first_cell_schedule_time (T1)\n",
    "        # and last_cell_executed_time (T2) fields for each rerun found\n",
    "        # by _parse. \n",
    "        self._match_cells_to_reruns()\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_cell_event(tokens: list[str]) -> tuple[CellID, TimeStampMS]:\n",
    "        \"\"\"\n",
    "        There are two cell events:\n",
    "         -Scheduled: occurs when the kernel recieves the request\n",
    "                     to queue a cell for execution. \n",
    "         -Executed: emitted by the kernel once a cell has finished. \n",
    "         \n",
    "        The perf messages for cell events follow the format of\n",
    "        PERF|<Event> time=...|exec id=...|cell_id_token=...\n",
    "        \"\"\"\n",
    "        time_token, _, cell_id_token = tokens\n",
    "        _, timestamp = time_token.split(\"=\")\n",
    "        _, cell_id = cell_id_token.split(\"=\")\n",
    "\n",
    "        return cell_id, float(timestamp)\n",
    "\n",
    "    def _handle_perf_line(self, line: str) -> None:\n",
    "        \"\"\"\n",
    "        Given a raw perf log line, parses it based on the perf event\n",
    "        and updates the parser datastructures. \n",
    "        \"\"\"\n",
    "        # First token is always PERF, skip\n",
    "        tokens = line.split(self.PERF_LINE_DELIM)[1:] # => Scheduled time=...|exec id=...|cell_id_token=...\n",
    "        \n",
    "        event_name_token = tokens[0] # Scheduled time\n",
    "        name, value = event_name_token.split(\"=\") # => Scheduled time, TIME \n",
    "        if name == \"Scheduled time\":\n",
    "            # Scheduled time=%f|exec id=%d|cell id=%s\n",
    "            # NOTE: We may have other cells not having to do with reran here. \n",
    "            cell_id, timestamp = self._parse_cell_event(tokens)\n",
    "            self._cell_scheduled_times.append((cell_id.strip(), timestamp)) # add to all cell scheduled time \n",
    "            \n",
    "        elif name == \"Executed time\":\n",
    "            # Executed time=%f|exec_id=%d|cell_id=%s\n",
    "            # NOTE: We may have other cells not having to do with reran here. \n",
    "            cell_id, timestamp = self._parse_cell_event(tokens)\n",
    "            self._cell_executed_times.append((cell_id.strip(), timestamp)) # add to all cell executed time\n",
    "            \n",
    "        elif name == \"Rerun start\":\n",
    "            # Rerun start=%d|Rerun cells=%s\n",
    "            rerun_stat = RerunPerfStat() # Create a new representation of a rerun event (segment). \n",
    "            rerun_stat.rerun_start_time = float(value)\n",
    "            _, rerun_cell_tokens = tokens[1].split(\"=\") # Get cells reran. \n",
    "            rerun_stat.reran_cells = [cell_id.strip() for cell_id in rerun_cell_tokens.split(\",\")]\n",
    "            self._rerun_stats.append(rerun_stat)\n",
    "            \n",
    "        elif name == \"Rerun end\":\n",
    "            # Rerun end=%f\n",
    "            # This one is the rerun end time that has a little bit overhead. \n",
    "            latest_rerun = self._rerun_stats[-1] # Get the latest reran object. \n",
    "            latest_rerun.rerun_end_time = float(value) # Set their end time => this marks the end of a rerun segment.  \n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid perf event: {line}\")\n",
    "        \n",
    "    def _parse(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Iterates over each line of the log file \n",
    "        for perf events\n",
    "        \"\"\"\n",
    "        with open(file_path) as fd:\n",
    "            for line in fd:\n",
    "                line_start_idx = line.find(\"PERF\")\n",
    "                if line_start_idx != -1:\n",
    "                    print(line)\n",
    "                    self._handle_perf_line(line[line_start_idx:])\n",
    "\n",
    "    def _match_cell_start(self, cur_rerun: RerunPerfStat):\n",
    "        \"\"\"\n",
    "        Iterates through the list of Scheduled events (scheduled_times)\n",
    "        to find the Schedule event time of each reran cell in\n",
    "        cur_rerun.\n",
    "        \n",
    "        First cell to be scheduled for rerun: \n",
    "        Sets the first_cell_schedule_time using the\n",
    "        earliest Schedule event timestamp of reran cells. \n",
    "        \"\"\"\n",
    "        to_remove_idx = []\n",
    "        reran_cells = set(cur_rerun.reran_cells)\n",
    "        for idx, (cell_id, timestamp) in enumerate(self._cell_scheduled_times):\n",
    "            if not reran_cells:\n",
    "                break\n",
    "            \n",
    "            # Time is organized top (recent) -> bottom (past)\n",
    "            if cell_id in reran_cells:\n",
    "                reran_cells.remove(cell_id)\n",
    "                cur_rerun.first_cell_schedule_time = min(\n",
    "                    cur_rerun.first_cell_schedule_time, timestamp\n",
    "                )\n",
    "                to_remove_idx.append(idx)\n",
    "        \n",
    "        # Remove all of this rerun segment cell's on schedule time since \n",
    "        # we already got the first scheduled cell's time. \n",
    "        self._cell_scheduled_times = [\n",
    "            cell for idx, cell in enumerate(self._cell_scheduled_times) if idx not in to_remove_idx\n",
    "        ]\n",
    "\n",
    "    def _match_cell_end(self, cur_rerun: RerunPerfStat):\n",
    "        \"\"\"\n",
    "        Iterates through the list of Executed events\n",
    "        to find the Executed event time of each reran cell in\n",
    "        cur_rerun.\n",
    "        \n",
    "        Sets the last_cell_executed_time using the\n",
    "        latest Exexcuted event timestamp of reran cells\n",
    "        \"\"\"\n",
    "        to_remove_idx = []\n",
    "        reran_cells = set(cur_rerun.reran_cells)\n",
    "        for idx, (cell_id, timestamp) in enumerate(self._cell_executed_times):\n",
    "            if not reran_cells:\n",
    "                break\n",
    "            \n",
    "            # All seen executed times will for sure be part of our rerun. \n",
    "            # Which means that they are the cells that got reran for this \n",
    "            # segment of the log file. \n",
    "            if cell_id in reran_cells:\n",
    "                reran_cells.remove(cell_id)\n",
    "                cur_rerun.last_cell_executed_time = max(\n",
    "                    cur_rerun.last_cell_executed_time, timestamp\n",
    "                )\n",
    "                to_remove_idx.append(idx)\n",
    "\n",
    "        # Remove all cells related to this rerun segment since we are done \n",
    "        # with it (extracted the last cell executed time). \n",
    "        self._cell_executed_times = [\n",
    "            cell for idx, cell in enumerate(self._cell_executed_times) if idx not in to_remove_idx\n",
    "        ]\n",
    "        \n",
    "    def _match_cells_to_reruns(self):\n",
    "        \"\"\"\n",
    "        For each rerun, match cell events to the rerun the\n",
    "        event was part of.\n",
    "        \"\"\"\n",
    "\n",
    "        # the earliest reruns are at the beginning of _rerun_stats list\n",
    "        # reverse the list so the earliest events are at the end\n",
    "        # then we pop the events off the end until rerun_queue is empty\n",
    "        rerun_queue = copy(self._rerun_stats)\n",
    "        rerun_queue.reverse()\n",
    "        \n",
    "        while rerun_queue:\n",
    "            cur_rerun = rerun_queue.pop()\n",
    "            self._match_cell_start(cur_rerun)\n",
    "            self._match_cell_end(cur_rerun)\n",
    "\n",
    "    @property\n",
    "    def rerun_perf_stats(self) -> list[RerunPerfStat]:\n",
    "        \"\"\" Public getter method to use the rerun stats for analysis. \"\"\"\n",
    "        return self._rerun_stats\n",
    "\n",
    "    def pretty_print_rerun_stats(self) -> None:\n",
    "        \"\"\" Formatted print of all rerun stats, cell ids are excluded. \"\"\"\n",
    "        out_msg = [\"Reruns:\"]\n",
    "        for idx, rerun in enumerate(self._rerun_stats):\n",
    "            rerun_msg = (\n",
    "                f\"Rerun idx: {idx}\\n\"\n",
    "                f\"Number of cells reran: {len(rerun.reran_cells)}\\n\"\n",
    "                f\"Rerun start timestamp: {rerun.rerun_start_time}ms\\n\"\n",
    "                f\"First cell scheduled timestamp: {rerun.first_cell_schedule_time}ms\\n\"\n",
    "                f\"Last cell executed timestamp: {rerun.last_cell_executed_time}ms\\n\"\n",
    "                f\"Rerun end timestamp: {rerun.rerun_end_time}ms\\n\"\n",
    "            )\n",
    "            out_msg.append(rerun_msg)\n",
    "        print(\"\\n\".join(out_msg))\n",
    "\n",
    "    def average_overhead(self) -> dict[int, list[float, int]]:\n",
    "        \"\"\"\n",
    "        Returns a dict\n",
    "        num cells in rerun -> average overhead of rerun in ms, num reruns. \n",
    "        see how rerun overhead changes as we get more cells that we need to rerun. \n",
    "        \"\"\"\n",
    "        ret = {}\n",
    "        for rerun in self._rerun_stats:\n",
    "            n_cells = len(rerun.reran_cells)\n",
    "            overhead = rerun.first_cell_schedule_time - rerun.rerun_start_time\n",
    "            if info := ret.get(n_cells):\n",
    "                info[0] += overhead\n",
    "                info[1] += 1 # accumulate reruns with this exact num of cells to rerun. \n",
    "            else:\n",
    "                ret[n_cells] = [overhead, 1]\n",
    "\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d505b-d2e0-480c-8411-26298d23d760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:57:24.666872Z",
     "iopub.status.busy": "2025-04-18T06:57:24.663856Z",
     "iopub.status.idle": "2025-04-18T06:57:24.678115Z",
     "shell.execute_reply": "2025-04-18T06:57:24.676892Z",
     "shell.execute_reply.started": "2025-04-18T06:57:24.666818Z"
    }
   },
   "outputs": [],
   "source": [
    "stat = PerfStat(perf_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b965c-a763-4f8d-bfc7-ee9395bad4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:57:25.108029Z",
     "iopub.status.busy": "2025-04-18T06:57:25.107643Z",
     "iopub.status.idle": "2025-04-18T06:57:25.124318Z",
     "shell.execute_reply": "2025-04-18T06:57:25.120116Z",
     "shell.execute_reply.started": "2025-04-18T06:57:25.108001Z"
    }
   },
   "outputs": [],
   "source": [
    "stat.pretty_print_rerun_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b07703-d46a-4d3b-8154-992740dc376a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T03:22:30.485151Z",
     "iopub.status.busy": "2025-04-18T03:22:30.484796Z",
     "iopub.status.idle": "2025-04-18T03:22:30.489046Z",
     "shell.execute_reply": "2025-04-18T03:22:30.488054Z",
     "shell.execute_reply.started": "2025-04-18T03:22:30.485126Z"
    }
   },
   "outputs": [],
   "source": [
    "print(stat.average_overhead())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da020a-95d0-43f3-a6ac-5246d326ecdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:58:20.790861Z",
     "iopub.status.busy": "2025-04-18T06:58:20.790468Z",
     "iopub.status.idle": "2025-04-18T06:58:20.799763Z",
     "shell.execute_reply": "2025-04-18T06:58:20.798486Z",
     "shell.execute_reply.started": "2025-04-18T06:58:20.790832Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_average_runtime_chart(rerun: RerunPerfStat) -> None:\n",
    "    processes = [\n",
    "        {\n",
    "            \"name\": \"Handling Rerun Signal\",\n",
    "            \"start\": 0,\n",
    "            \"stop\": rerun.first_cell_schedule_time - rerun.rerun_start_time,\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"Cells executing (Rerun)\",\n",
    "            \"start\": rerun.first_cell_schedule_time - rerun.rerun_start_time,\n",
    "            \"stop\": rerun.rerun_end_time - rerun.rerun_start_time,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    process_names = [p[\"name\"] for p in processes]\n",
    "    start_times = [p[\"start\"] for p in processes]\n",
    "    durations = [p[\"stop\"] - p[\"start\"] for p in processes]\n",
    "    y_positions = np.arange(len(processes))\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot horizontal bars (Gantt chart)\n",
    "    plt.barh(y_positions, durations, left=start_times, height=0.4, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.yticks(y_positions, process_names)\n",
    "    plt.xlabel('Time (milliseconds)')\n",
    "    plt.ylabel('Processes')\n",
    "    plt.title('Process Latency (Start and Stop Times)')\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout to prevent label clipping\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb2632-42a1-4ae9-96fb-0744e1c58f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T06:58:21.697526Z",
     "iopub.status.busy": "2025-04-18T06:58:21.697116Z",
     "iopub.status.idle": "2025-04-18T06:58:21.813663Z",
     "shell.execute_reply": "2025-04-18T06:58:21.813375Z",
     "shell.execute_reply.started": "2025-04-18T06:58:21.697494Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_average_runtime_chart(stat.rerun_perf_stats[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29c6c7-650e-4bdf-92b8-c4ad8bccf0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
